{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1 style=\"font-size:2.5vw\"> AML Project 1 </h1></center>\n",
    "\n",
    "---\n",
    "<div style=\"display:flex; flex-direction:row; width:35%; justify-content : space-between\">\n",
    "    <div style = \"display : flex, flex-direction : column\">\n",
    "        <div><b><font color = \"#3285d3\">Authors</font></b></div>\n",
    "        <div><b><font color = \"#3285d3\">Date</font></b></div>\n",
    "    </div>\n",
    "    <div style = \"display : flex, flex-direction : column\">\n",
    "        <div><b>&nbsp;&nbsp;:&nbsp;&nbsp;</b></div>\n",
    "        <div><b>&nbsp;&nbsp;:&nbsp;&nbsp;</b></div>\n",
    "    </div>\n",
    "    <div style = \"display : flex, flex-direction : column\">\n",
    "        <div>Albert Roathel, Marcel Affi</div>\n",
    "        <div>April 2021</div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project outline\n",
    "\n",
    "1. [Preprocessing Datasets](#Preprocessing_Datasets)\n",
    "2. [Measures of Classification](#measures_of_classification)\n",
    "3. [Optimization Algorithms](#optimization_algorithms)\n",
    "4. [Experiments](#experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Preprocessing_Datasets'></a>\n",
    "## Preprocessing Datasets\n",
    "\n",
    "We chose to work with the following datasets, each consisting of binary class variables : \n",
    "* Titanic\n",
    "* Students\n",
    "\n",
    "TODO: ADD MORE DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:25:12.851024Z",
     "start_time": "2021-03-27T15:25:10.362194Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "# Students.csv\n",
    "!curl -O https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip\n",
    "!unzip -o student.zip\n",
    "\n",
    "# Titanic.csv\n",
    "!curl -O -k https://www.openml.org/data/get_csv/16826755/phpMYEkMl\n",
    "!mv phpMYEkMl titanic.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:08:17.757251Z",
     "start_time": "2021-03-27T16:08:16.178924Z"
    }
   },
   "outputs": [],
   "source": [
    "!curl -O -k https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:25:48.476300Z",
     "start_time": "2021-03-27T15:25:40.422581Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import (NeighborhoodComponentsAnalysis,KNeighborsClassifier)\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Seaborn properties\n",
    "sns.set(rc={'figure.figsize':(11.7,5), 'figure.dpi':200})\n",
    "\n",
    "# plotty properties\n",
    "def show_plot(fig):\n",
    "    fig.update_layout({\n",
    "        'plot_bgcolor': 'rgba(10, 10, 10, 0.1)',\n",
    "        'paper_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "        'xaxis': {\n",
    "            'showgrid': False,\n",
    "            'showline': False,\n",
    "        },\n",
    "        'yaxis': {\n",
    "            'showgrid': False,\n",
    "            'showline': False,\n",
    "        }\n",
    "    })\n",
    "    fig.show()\n",
    "\n",
    "# Ignore numpy overflow warnings in sigmoid function\n",
    "np.seterr( over='ignore' );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:25:48.611538Z",
     "start_time": "2021-03-27T15:25:48.480656Z"
    }
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('titanic.csv')\n",
    "titanic.cabin = titanic.cabin.str[0].value_counts()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:25:48.699249Z",
     "start_time": "2021-03-27T15:25:48.663324Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in titanic.columns:\n",
    "    missing = (titanic[column] == '?').mean()\n",
    "    if missing > 0:\n",
    "        print(column, missing)\n",
    "        titanic.loc[titanic[column] == '?', column] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boat and body will be omitted as most of observations do not have this value; home.dest and boat has too many potential values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:26:07.213965Z",
     "start_time": "2021-03-27T15:26:07.188286Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = titanic[['age', 'fare']].isna().apply(any, axis=1)\n",
    "titanic = titanic.loc[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:11:40.949080Z",
     "start_time": "2021-03-27T16:11:40.893915Z"
    }
   },
   "outputs": [],
   "source": [
    "banknote = pd.read_csv('data_banknote_authentication.txt', names=['var', 'skew', 'kurt', 'entr', 'y'])\n",
    "banknote.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:26:07.844416Z",
     "start_time": "2021-03-27T15:26:07.839607Z"
    }
   },
   "outputs": [],
   "source": [
    "def onehotencoding(series):\n",
    "    N = len(series)\n",
    "    levels = series.unique()\n",
    "    data = np.zeros([N, len(levels)])\n",
    "    for i, level in enumerate(levels):\n",
    "        data[series == level, i] = 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='measures_of_classification'></a>\n",
    "## Measures of classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:13:05.198969Z",
     "start_time": "2021-03-27T16:13:05.182430Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_scores(y_true, y_pred):\n",
    "    unique_classes = np.unique(y_true)\n",
    "    conf_matrix = np.zeros([len(unique_classes), len(unique_classes)])\n",
    "    conf_matrix[0, 0] = np.sum(y_pred[y_true==0] == 0)\n",
    "    conf_matrix[1, 1] = np.sum(y_pred[y_true==1] == 1)\n",
    "    conf_matrix[0, 1] = np.sum(y_pred[y_true==0] == 1)\n",
    "    conf_matrix[1, 0] = np.sum(y_pred[y_true==1] == 0)\n",
    "    \n",
    "    acc = np.sum(np.diag(conf_matrix)) / np.sum(conf_matrix)\n",
    "    recall = np.diag(conf_matrix) / np.sum(conf_matrix, 1)\n",
    "    precision = np.diag(conf_matrix) / np.sum(conf_matrix, 0)\n",
    "    conf_matrix = pd.DataFrame(conf_matrix, columns=[\"0\", \"1\"])\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    results = dict(conf_matrix=conf_matrix, acc=acc, recall=recall, precision=precision, f1=f1)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='optimization_algorithms'></a>\n",
    "## Optimization Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:26:17.550954Z",
     "start_time": "2021-03-27T15:26:17.546690Z"
    }
   },
   "outputs": [],
   "source": [
    "# sigmoid function; models the probability in logistic regression\n",
    "def sigmoid(X, beta):\n",
    "    exp = np.exp(np.dot(X, -beta))\n",
    "    return 1 / (1 + exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:08:23.294179Z",
     "start_time": "2021-03-27T18:08:23.289437Z"
    }
   },
   "outputs": [],
   "source": [
    "# cost function for log likelihood optimization\n",
    "def cost_function_der(X, y, beta):\n",
    "    return np.dot(X.T, (y - sigmoid(X, beta)))\n",
    "\n",
    "def cost_function(X, y, beta):\n",
    "    tmp = X.dot(np.array(beta))\n",
    "    return tmp.dot(y) - np.log(1 + np.exp(tmp)).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:49:55.167673Z",
     "start_time": "2021-03-27T18:49:55.159764Z"
    }
   },
   "outputs": [],
   "source": [
    "# gradient descent approach for minimazation\n",
    "def gradient_descent(X, y, n_iter=1000, l_rate=1e-4, tolerance=0.001, get_cost=False):\n",
    "    N, p = X.shape\n",
    "    # initial betas\n",
    "    beta = np.random.randn(p)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        _beta = beta.copy()\n",
    "        grad = cost_function_der(X, y, beta)\n",
    "        beta += grad * l_rate\n",
    "        tol = np.sum(abs(beta - _beta))\n",
    "        if tolerance:\n",
    "            if tol < tolerance and tolerance:\n",
    "                return beta if not get_cost else (beta, cost_function(X, y, beta))\n",
    "    \n",
    "    return beta if not get_cost else (beta, cost_function(X, y, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:50:16.547493Z",
     "start_time": "2021-03-27T18:50:16.530652Z"
    }
   },
   "outputs": [],
   "source": [
    "def SGD(X, y, n_iter=1000, l_rate=1e-4, n_chunk=50, tolerance=0.001, get_cost=False):\n",
    "    N, p = X.shape\n",
    "    # initial betas\n",
    "    beta = np.random.randn(p)\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        _beta = beta.copy()\n",
    "        ind = np.arange(N)\n",
    "        np.random.shuffle(ind)\n",
    "        for i in range(0, N, n_chunk):\n",
    "            subset = ind[i:min(i + n_chunk, N) + 1]\n",
    "            grad = cost_function_der(X, y, beta)\n",
    "            update = grad * l_rate\n",
    "            beta += update\n",
    "        tol = np.sum(abs(beta - _beta)) \n",
    "        if tolerance:\n",
    "            if tol < tolerance:\n",
    "                return beta if not get_cost else (beta, cost_function(X, y, beta))\n",
    "    return beta if not get_cost else (beta, cost_function(X, y, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:50:31.573839Z",
     "start_time": "2021-03-27T18:50:31.564679Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : adjust for intercept\n",
    "def IRLS(X, y, n_iter=1000, w_init = 1, d = 0.5, tolerance = 0.001, get_cost=False):\n",
    "    n,p = X.shape\n",
    "    delta = np.array(np.repeat(d, n)).reshape(1,n)\n",
    "    w = np.repeat(1, n)\n",
    "    W = np.diag( w )\n",
    "    B = np.dot( np.linalg.inv( X.T.dot(W).dot(X) ), ( X.T.dot(W).dot(y) ) )\n",
    "    for _ in range(n_iter):\n",
    "        _B = B.copy()\n",
    "        _w = abs(y - X.dot(B)).T\n",
    "        w = float(1)/np.maximum( delta, _w )\n",
    "        W = np.diag( w[0] )\n",
    "        B = np.dot( np.linalg.inv( X.T.dot(W).dot(X) ), \n",
    "         ( X.T.dot(W).dot(y) ) )\n",
    "        tol = np.sum( abs( B - _B ) ) \n",
    "        if tolerance:\n",
    "            if tol < tolerance:\n",
    "                return B if not get_cost else (B, cost_function(X, y, beta))\n",
    "    return B if not get_cost else (B, cost_function(X, y, beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='experiments'></a>\n",
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:48:29.262092Z",
     "start_time": "2021-03-27T18:48:29.248011Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "# I removed some of the variables that seemed unnecessary\n",
    "\n",
    "#for column in ['pclass', 'sex', 'sibsp', 'parch']:\n",
    "for column in ['pclass', 'sex', 'parch']:\n",
    "    data.append(onehotencoding(titanic[column]))\n",
    "#for column in ['age', 'fare']:\n",
    "for column in ['age']:\n",
    "    data.append(titanic[column].values.astype(float).reshape([len(titanic), 1]))\n",
    "\n",
    "X = np.concatenate(data, axis=1)\n",
    "y = titanic.survived.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:00:08.863253Z",
     "start_time": "2021-03-27T16:00:08.823677Z"
    }
   },
   "outputs": [],
   "source": [
    "titanic_plot = titanic.copy()\n",
    "categories = ['pclass','sex',\n",
    "              'parch', 'fare']\n",
    "\n",
    "#titanic_plot.age = titanic.age.astype(float).astype(int)\n",
    "titanic_plot.fare = titanic.fare.astype(float)\n",
    "titanic_plot.pclass = titanic.pclass * 20\n",
    "titanic_plot.parch = titanic.parch * 100\n",
    "#titanic_plot.sibsp = titanic.sibsp * 100\n",
    "titanic_plot.sex = titanic.sex.apply(lambda sex : 0 if sex == \"female\" else 100)\n",
    "surviveded_mean_vals = titanic_plot.loc[titanic_plot['survived'] == 1][categories].mean().values.tolist()\n",
    "not_survived_mean_vals = titanic_plot.loc[titanic_plot['survived'] == 0][categories].mean().values.tolist()\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "      r=surviveded_mean_vals,\n",
    "      theta=categories,\n",
    "      fill='toself',\n",
    "      name='Survived'\n",
    "))\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "      r=not_survived_mean_vals,\n",
    "      theta=categories,\n",
    "      fill='toself',\n",
    "      name='Not Survived'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "  polar=dict(\n",
    "    radialaxis=dict(\n",
    "      visible=True,\n",
    "      range=[0, 100]\n",
    "    )),\n",
    "  showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:50:35.548866Z",
     "start_time": "2021-03-27T18:50:35.543017Z"
    }
   },
   "outputs": [],
   "source": [
    "X = banknote.values[:, :3]\n",
    "y = banknote.values[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:50:35.720983Z",
     "start_time": "2021-03-27T18:50:35.712012Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:50:35.951225Z",
     "start_time": "2021-03-27T18:50:35.839286Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "beta = gradient_descent(X_train, y_train, l_rate=1e-4)\n",
    "pred = (sigmoid(X_test, beta) > 0.5).astype(int)\n",
    "results = calculate_scores(y_test, pred)\n",
    "print(f'The resulting accuracy is {results[\"acc\"]*100:.2f}%')\n",
    "results['conf_matrix'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:50:37.598851Z",
     "start_time": "2021-03-27T18:50:37.113877Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "beta = SGD(X_train, y_train, l_rate=1e-4)\n",
    "pred = (sigmoid(X_test, beta) > 0.5).astype(int)\n",
    "results = calculate_scores(y_test, pred)\n",
    "print(f'The resulting accuracy is {results[\"acc\"]*100:.2f}%')\n",
    "results['conf_matrix'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:50:37.871493Z",
     "start_time": "2021-03-27T18:50:37.758634Z"
    }
   },
   "outputs": [],
   "source": [
    "beta = IRLS(X_train, y_train, d=0.01)\n",
    "pred = (sigmoid(X_test, beta) > 0.5).astype(int)\n",
    "results = calculate_scores(y_test, pred)\n",
    "print(f'The resulting accuracy is {results[\"acc\"]*100:.2f}%')\n",
    "results['conf_matrix'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance over iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:50:40.851524Z",
     "start_time": "2021-03-27T18:50:40.819324Z"
    }
   },
   "outputs": [],
   "source": [
    "def performance_over_iterations(X, y, iterations : int, opt_method, n=10, tol=None):\n",
    "    acc_list = []\n",
    "    for i in range(n):\n",
    "        beta = opt_method(X, y, n_iter = iterations, tolerance=tol)\n",
    "        pred = (sigmoid(X_test, beta) > 0.5).astype(int)\n",
    "        acc_list.append(calculate_scores(y_test, pred)['acc'])\n",
    "    return [iterations, np.mean(acc_list)]\n",
    "\n",
    "from_iter, to_iter, step_size = 20, 1020, 10\n",
    "from_iter, to_iter, step_size = 1, 51, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:50:43.965561Z",
     "start_time": "2021-03-27T18:50:42.050921Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "gd_iter_acc_list = [performance_over_iterations(X_train, y_train, iters, gradient_descent) \n",
    "                    for iters in tqdm(range(from_iter, to_iter, step_size))]\n",
    "gd_iter_acc = pd.DataFrame (gd_iter_acc_list,columns=['Iteration', 'Accuracy'])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data= gd_iter_acc, x = \"Iteration\", y = \"Accuracy\").set_title(\"Gradient Descent accuracy / iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:51:04.313473Z",
     "start_time": "2021-03-27T18:50:47.556645Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "sgd_iter_acc_list = [performance_over_iterations(X_train, y_train, iters, SGD) \n",
    "                     for iters in tqdm(range(from_iter, to_iter, step_size))]\n",
    "sgd_iter_acc = pd.DataFrame (sgd_iter_acc_list,columns=['Iteration', 'Accuracy'])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data= sgd_iter_acc, x = \"Iteration\", y = \"Accuracy\").set_title(\"Stochastic Gradient Descent accuracy / iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:51:52.981442Z",
     "start_time": "2021-03-27T18:51:04.317216Z"
    }
   },
   "outputs": [],
   "source": [
    "irls_iter_acc_list = [performance_over_iterations(X_train, y_train, iters, IRLS) \n",
    "                      for iters in tqdm(range(from_iter, to_iter, step_size))]\n",
    "irls_iter_acc = pd.DataFrame (irls_iter_acc_list,columns=['Iteration', 'Accuracy'])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data= irls_iter_acc, x = \"Iteration\", y = \"Accuracy\").set_title(\"IRLS accuracy / iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:52:10.570737Z",
     "start_time": "2021-03-27T18:52:10.564864Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost_over_iterations(X, y, iterations : int, opt_method, n=10, tol=None):\n",
    "    cost_list = []\n",
    "    for i in range(n):\n",
    "        beta, cost = opt_method(X, y, n_iter = iterations, tolerance=None, get_cost=True)\n",
    "        cost_list.append(cost)\n",
    "    return [iterations, np.mean(cost_list)]\n",
    "\n",
    "from_iter, to_iter, step_size = 1, 51, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:52:13.187382Z",
     "start_time": "2021-03-27T18:52:11.543515Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "gd_iter_acc_list = [cost_over_iterations(X_train, y_train, iters, gradient_descent) \n",
    "                    for iters in tqdm(range(from_iter, to_iter, step_size))]\n",
    "gd_iter_acc = pd.DataFrame (gd_iter_acc_list,columns=['Iteration', 'Log likelihood'])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data= gd_iter_acc, x = \"Iteration\", y = \"Log likelihood\").set_title(\"Gradient Descent Log likelihood / iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:52:29.113793Z",
     "start_time": "2021-03-27T18:52:13.191712Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "gd_iter_acc_list = [cost_over_iterations(X_train, y_train, iters, SGD) \n",
    "                    for iters in tqdm(range(from_iter, to_iter, step_size))]\n",
    "gd_iter_acc = pd.DataFrame (gd_iter_acc_list,columns=['Iteration', 'Log likelihood'])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data= gd_iter_acc, x = \"Iteration\", y = \"Log likelihood\").set_title(\"SGD Log likelihood / iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:53:09.019865Z",
     "start_time": "2021-03-27T18:52:29.117941Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "gd_iter_acc_list = [cost_over_iterations(X_train, y_train, iters, IRLS) \n",
    "                    for iters in tqdm(range(from_iter, to_iter, step_size))]\n",
    "gd_iter_acc = pd.DataFrame (gd_iter_acc_list,columns=['Iteration', 'Log likelihood'])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data= gd_iter_acc, x = \"Iteration\", y = \"Log likelihood\").set_title(\"IRLS Log likelihood / iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T19:01:09.038536Z",
     "start_time": "2021-03-27T19:01:09.030059Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost_over_iterations(X, y, iterations, opt_method, n=10, tol=1e-4, l_rate=0.01):\n",
    "    cost_list = []\n",
    "    for i in range(n):\n",
    "        beta, cost = opt_method(X, y, iterations, l_rate=l_rate, tolerance=None, get_cost=True)\n",
    "        cost_list.append(cost)\n",
    "    return [iterations, l_rate, np.mean(cost_list)]\n",
    "\n",
    "from_iter, to_iter, step_size = 1, 51, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T19:14:02.235683Z",
     "start_time": "2021-03-27T19:13:55.912396Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "gd_iter_acc_list = [cost_over_iterations(X_train, y_train, iters, gradient_descent, l_rate=l_rate) \n",
    "                    for iters in tqdm(range(from_iter, to_iter, step_size))\n",
    "                    for l_rate in np.logspace(-2, -6, 5)]\n",
    "gd_iter_acc = pd.DataFrame (gd_iter_acc_list,columns=['Iteration', 'lr', 'Log likelihood'])\n",
    "\n",
    "px.line(gd_iter_acc, x='Iteration', y='Log likelihood', color='lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T19:10:49.114113Z",
     "start_time": "2021-03-27T19:09:43.415899Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "gd_iter_acc_list = [cost_over_iterations(X_train, y_train, iters, SGD, l_rate=l_rate) \n",
    "                    for iters in tqdm(range(from_iter, to_iter, step_size))\n",
    "                    for l_rate in np.logspace(-2, -6, 5)]\n",
    "gd_iter_acc = pd.DataFrame (gd_iter_acc_list,columns=['Iteration', 'lr', 'Log likelihood'])\n",
    "\n",
    "px.line(gd_iter_acc, x='Iteration', y='Log likelihood', color='lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing against other methods form mentioned libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:54:06.547573Z",
     "start_time": "2021-03-27T18:54:06.520966Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, max_iter=1000).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:53:34.336117Z",
     "start_time": "2021-03-27T18:53:33.875224Z"
    }
   },
   "outputs": [],
   "source": [
    "nca = NeighborhoodComponentsAnalysis(random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "nca_pipe.fit(X_train, y_train)\n",
    "nca_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA ftom sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T18:53:34.767930Z",
     "start_time": "2021-03-27T18:53:34.746504Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QDA from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:42:27.752712Z",
     "start_time": "2021-03-27T16:42:27.739009Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mock data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:38:50.443789Z",
     "start_time": "2021-03-27T15:38:47.308197Z"
    }
   },
   "outputs": [],
   "source": [
    "# lets create simple dataset consiting of N point in R2 that can belong to 2 classes\n",
    "N = 1000\n",
    "X = np.random.randn(N * 2).reshape(N, 2) - 1\n",
    "X[:N//2] = X[:N//2] + 2\n",
    "y = np.array([0] * (N//2) + [1] * (N//2))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=y)\n",
    "show_plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:38:50.450092Z",
     "start_time": "2021-03-27T15:38:50.446491Z"
    }
   },
   "outputs": [],
   "source": [
    "# add column of ones to include intercept in the model\n",
    "intercept = np.ones((X.shape[0], 1))\n",
    "X = np.concatenate((intercept, X), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:38:50.579579Z",
     "start_time": "2021-03-27T15:38:50.459833Z"
    }
   },
   "outputs": [],
   "source": [
    "beta = gradient_descent(X, y, l_rate=1e-4)\n",
    "pred = (sigmoid(X, beta) > 0.5).astype(int)\n",
    "conf_matrix, acc = calculate_scores(y, pred)\n",
    "print(f'The resulting accuracy is {acc*100:.2f}%')\n",
    "conf_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:38:52.380324Z",
     "start_time": "2021-03-27T15:38:50.584641Z"
    }
   },
   "outputs": [],
   "source": [
    "beta = SGD(X, y, l_rate=1e-4)\n",
    "pred = (sigmoid(X, beta) > 0.5).astype(int)\n",
    "conf_matrix, acc = calculate_scores(y, pred)\n",
    "print(f'The resulting accuracy is {acc*100:.2f}%')\n",
    "conf_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:38:52.585541Z",
     "start_time": "2021-03-27T15:38:52.387165Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is low because IRLS is fucking up with the added intercept column, if you remove the intercept\n",
    "# works as intended, I'll need to check on that maybe tomorrow\n",
    "beta = IRLS(X, y, n_iter=1000, w_init = 1, d=0.5)\n",
    "pred = (sigmoid(X, beta) > 0.5).astype(int)\n",
    "conf_matrix, acc = calculate_scores(y, pred)\n",
    "print(f'The resulting accuracy is {acc*100:.2f}%')\n",
    "conf_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:38:52.977777Z",
     "start_time": "2021-03-27T15:38:52.602541Z"
    }
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(-5, 5, 100)\n",
    "yy = np.linspace(-5, 5, 100)\n",
    "xx, yy = np.meshgrid(xx, yy)\n",
    "xx, yy = xx.flatten(), yy.flatten()\n",
    "mock_data = np.array([np.ones(len(xx)), xx, yy]).T\n",
    "values = sigmoid(mock_data, beta)\n",
    "go.Figure(\n",
    "    [\n",
    "        go.Contour(x=xx, y=yy, z=values),\n",
    "        go.Scatter(x=X[y==0, 1], y=X[y==0, 2], mode='markers', marker_color='red'),\n",
    "        go.Scatter(x=X[y==1, 1], y=X[y==1, 2], mode='markers', marker_color='blue')\n",
    "    ],\n",
    "    layout=dict(\n",
    "        xaxis=dict(scaleanchor='y', scaleratio=1),\n",
    "        width=600, height=600,\n",
    "        showlegend=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
