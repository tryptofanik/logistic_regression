{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1 style=\"font-size:2.5vw\"> AML Project 1 </h1></center>\n",
    "\n",
    "---\n",
    "<div style=\"display:flex; flex-direction:row; width:35%; justify-content : space-between\">\n",
    "    <div style = \"display : flex, flex-direction : column\">\n",
    "        <div><b><font color = \"#3285d3\">Authors</font></b></div>\n",
    "        <div><b><font color = \"#3285d3\">Date</font></b></div>\n",
    "    </div>\n",
    "    <div style = \"display : flex, flex-direction : column\">\n",
    "        <div><b>&nbsp;&nbsp;:&nbsp;&nbsp;</b></div>\n",
    "        <div><b>&nbsp;&nbsp;:&nbsp;&nbsp;</b></div>\n",
    "    </div>\n",
    "    <div style = \"display : flex, flex-direction : column\">\n",
    "        <div>Albert Roathel, Marcel Affi</div>\n",
    "        <div>April 2021</div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project outline\n",
    "\n",
    "1. [Preprocessing Datasets](#Preprocessing_Datasets)\n",
    "2. [Measures of Classification](#measures_of_classification)\n",
    "3. [Optimization Algorithms](#optimization_algorithms)\n",
    "4. [Experiments](#experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Preprocessing_Datasets'></a>\n",
    "## Preprocessing Datasets\n",
    "\n",
    "We chose to work with the following datasets, each consisting of binary class variables : \n",
    "* Diabetes\n",
    "* Students\n",
    "\n",
    "TODO: ADD MORE DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:07.007322Z",
     "start_time": "2021-04-07T16:29:03.860635Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "# Students.csv\n",
    "!curl -O https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip\n",
    "!unzip -o student.zip\n",
    "\n",
    "# Banknote authentication\n",
    "!curl -O -k https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:14.852789Z",
     "start_time": "2021-04-07T16:29:07.011734Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import (NeighborhoodComponentsAnalysis,KNeighborsClassifier)\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Seaborn properties\n",
    "sns.set(rc={'figure.figsize':(11.7,5), 'figure.dpi':200})\n",
    "\n",
    "# plotty properties\n",
    "def show_plot(fig):\n",
    "    fig.update_layout({\n",
    "        'plot_bgcolor': 'rgba(10, 10, 10, 0.1)',\n",
    "        'paper_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "        'xaxis': {\n",
    "            'showgrid': False,\n",
    "            'showline': False,\n",
    "        },\n",
    "        'yaxis': {\n",
    "            'showgrid': False,\n",
    "            'showline': False,\n",
    "        }\n",
    "    })\n",
    "    fig.show()\n",
    "\n",
    "# Ignore numpy overflow warnings in sigmoid function\n",
    "np.seterr( over='ignore' );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:14.893550Z",
     "start_time": "2021-04-07T16:29:14.856563Z"
    }
   },
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('diabetes2.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.667867Z",
     "start_time": "2021-04-07T16:29:14.898785Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_radar_plot(df, target_name, category_0_label, category_1_label):\n",
    "    input_df = df.copy().iloc[:,0:-1]\n",
    "    \n",
    "    #Scaling variables\n",
    "    scaler = MinMaxScaler()\n",
    "    input_df = pd.DataFrame(scaler.fit_transform(input_df), columns=input_df.columns)\n",
    "\n",
    "    categories = input_df.columns.to_list()\n",
    "    means_0 = input_df.loc[df[target_name] == 0].mean().to_list()\n",
    "    means_1 = input_df.loc[df[target_name] == 1].mean().to_list()\n",
    "\n",
    "    targets = df.iloc[:, -1]\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    \n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "          r=means_1,\n",
    "          theta=categories,\n",
    "          fill='toself',\n",
    "          name=category_1_label,\n",
    "    ))\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "          r=means_0,\n",
    "          theta=categories,\n",
    "          fill='toself',\n",
    "          name=category_0_label\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"top\",\n",
    "            y=-0.1,\n",
    "            xanchor=\"left\",\n",
    "            x=0.375\n",
    "        ),\n",
    "\n",
    "      polar=dict(\n",
    "        radialaxis=dict(\n",
    "          visible=True,\n",
    "          range=[0, 1]\n",
    "        )),\n",
    "      showlegend=True\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "get_radar_plot(diabetes, target_name='Outcome', category_0_label = \"Is diabetic\", category_1_label = \"Is not diabetic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.681740Z",
     "start_time": "2021-04-07T16:29:15.672603Z"
    }
   },
   "outputs": [],
   "source": [
    "diabetes.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.692319Z",
     "start_time": "2021-04-07T16:29:15.686967Z"
    }
   },
   "outputs": [],
   "source": [
    "len(diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.699957Z",
     "start_time": "2021-04-07T16:29:15.697660Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For one hot encoding\n",
    "#sex_enc = pd.get_dummies(titanic.sex)\n",
    "#pclass_enc = pd.get_dummies(titanic.pclass)\n",
    "#parch_enc = pd.get_dummies(titanic.parch)\n",
    "#input_df = [sex_enc, pclass_enc, parch_enc]\n",
    "#input_df = pd.concat(input_df)\n",
    "#diabetes.iloc[:,0:-1]input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.708301Z",
     "start_time": "2021-04-07T16:29:15.703546Z"
    }
   },
   "outputs": [],
   "source": [
    "def trimm_correlated(df_in, threshold):\n",
    "    df_corr = df_in.corr(method='pearson', min_periods=1)\n",
    "    df_not_correlated = ~(df_corr.mask(np.tril(np.ones([len(df_corr)]*2, dtype=bool))).abs() > threshold).any()\n",
    "    un_corr_idx = df_not_correlated.loc[df_not_correlated[df_not_correlated.index] == True].index\n",
    "    df_out = df_in[un_corr_idx]\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.720959Z",
     "start_time": "2021-04-07T16:29:15.711002Z"
    }
   },
   "outputs": [],
   "source": [
    "diabetes_trim = trimm_correlated(diabetes.iloc[:,0:-1], 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.739762Z",
     "start_time": "2021-04-07T16:29:15.723208Z"
    }
   },
   "outputs": [],
   "source": [
    "banknote = pd.read_csv('data_banknote_authentication.txt', names=['var', 'skew', 'kurt', 'entr', 'y'])\n",
    "banknote.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.751981Z",
     "start_time": "2021-04-07T16:29:15.742668Z"
    }
   },
   "outputs": [],
   "source": [
    "banknote_trim = trimm_correlated(banknote.iloc[:,0:-1], 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.758764Z",
     "start_time": "2021-04-07T16:29:15.755168Z"
    }
   },
   "outputs": [],
   "source": [
    "X = banknote_trim.values\n",
    "y = banknote['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.765371Z",
     "start_time": "2021-04-07T16:29:15.761411Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.hstack([np.ones((X.shape[0], 1)), X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.772872Z",
     "start_time": "2021-04-07T16:29:15.768251Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = dict(\n",
    "    banknote=[banknote_trim.values, banknote['y'].values],\n",
    "    diabetes=[diabetes_trim.values, diabetes.Outcome.values]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='measures_of_classification'></a>\n",
    "## Measures of classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.793328Z",
     "start_time": "2021-04-07T16:29:15.776137Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_scores(y_true, y_pred, beta=None):\n",
    "    unique_classes = np.unique(y_true)\n",
    "    conf_matrix = np.zeros([len(unique_classes), len(unique_classes)])\n",
    "    conf_matrix[0, 0] = np.sum(y_pred[y_true==0] == 0)\n",
    "    conf_matrix[1, 1] = np.sum(y_pred[y_true==1] == 1)\n",
    "    conf_matrix[0, 1] = np.sum(y_pred[y_true==0] == 1)\n",
    "    conf_matrix[1, 0] = np.sum(y_pred[y_true==1] == 0)\n",
    "    \n",
    "    R2=None\n",
    "    if beta is not None:\n",
    "        beta_null = beta.copy()\n",
    "        beta_null[1:] = 0\n",
    "        R2 = 1 - cost_function(X_test, y_test, beta) / cost_function(X_test, y_test, beta_null)\n",
    "    \n",
    "    acc = np.sum(np.diag(conf_matrix)) / np.sum(conf_matrix)\n",
    "    recall = np.diag(conf_matrix) / np.sum(conf_matrix, 1)\n",
    "    precision = np.diag(conf_matrix) / np.sum(conf_matrix, 0)\n",
    "    conf_matrix = pd.DataFrame(conf_matrix, columns=[\"0\", \"1\"])\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    results = dict(conf_matrix=conf_matrix, acc=acc, recall=recall, precision=precision, f1=f1, R2=R2)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='optimization_algorithms'></a>\n",
    "## Optimization Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.809984Z",
     "start_time": "2021-04-07T16:29:15.802069Z"
    }
   },
   "outputs": [],
   "source": [
    "# sigmoid function; models the probability in logistic regression\n",
    "def sigmoid(X, beta):\n",
    "    exp = np.exp(np.dot(X, -beta))\n",
    "    return 1 / (1 + exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.828103Z",
     "start_time": "2021-04-07T16:29:15.818758Z"
    }
   },
   "outputs": [],
   "source": [
    "# cost function for log likelihood optimization\n",
    "def cost_function_der(X, y, beta):\n",
    "    return np.dot(X.T, (y - sigmoid(X, beta)))\n",
    "\n",
    "def cost_function(X, y, beta):\n",
    "    tmp = X.dot(np.array(beta))\n",
    "    return tmp.dot(y) - np.log(1 + np.exp(tmp)).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.845056Z",
     "start_time": "2021-04-07T16:29:15.834161Z"
    }
   },
   "outputs": [],
   "source": [
    "# gradient descent approach for minimazation\n",
    "def gradient_descent(X, y, n_iter=1000, l_rate=1e-4, tolerance=0.001, get_cost=False):\n",
    "    N, p = X.shape\n",
    "    # initial betas\n",
    "    beta = np.random.randn(p)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        _beta = beta.copy()\n",
    "        grad = cost_function_der(X, y, beta)\n",
    "        beta += grad * l_rate\n",
    "        tol = np.sum(abs(beta - _beta))\n",
    "        if tolerance:\n",
    "            if tol < tolerance and tolerance:\n",
    "                return beta if not get_cost else (beta, cost_function(X, y, beta))\n",
    "    \n",
    "    return beta if not get_cost else (beta, cost_function(X, y, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.862904Z",
     "start_time": "2021-04-07T16:29:15.847737Z"
    }
   },
   "outputs": [],
   "source": [
    "def SGD(X, y, n_iter=1000, l_rate=1e-4, n_chunk=50, tolerance=0.001, get_cost=False):\n",
    "    N, p = X.shape\n",
    "    # initial betas\n",
    "    beta = np.random.randn(p)\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        _beta = beta.copy()\n",
    "        ind = np.arange(N)\n",
    "        np.random.shuffle(ind)\n",
    "        for i in range(0, N, n_chunk):\n",
    "            subset = ind[i:min(i + n_chunk, N) + 1]\n",
    "            grad = cost_function_der(X, y, beta)\n",
    "            update = grad * l_rate\n",
    "            beta += update\n",
    "        tol = np.sum(abs(beta - _beta)) \n",
    "        if tolerance:\n",
    "            if tol < tolerance:\n",
    "                return beta if not get_cost else (beta, cost_function(X, y, beta))\n",
    "    return beta if not get_cost else (beta, cost_function(X, y, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.879338Z",
     "start_time": "2021-04-07T16:29:15.867152Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def IRLS(X, y, n_iter=1000, tolerance=0.0001, get_cost=False):\n",
    "    n, p = X.shape\n",
    "    w = np.ones(n)\n",
    "    W = np.diag(w)\n",
    "    B = np.dot(np.linalg.inv(X.T.dot(W).dot(X)), (X.T.dot(W).dot(y)))\n",
    "    for i in range(n_iter):\n",
    "        p = sigmoid(X, B)\n",
    "        w = p * (1 - p)\n",
    "        W = np.diag(w)\n",
    "        z = X.dot(B) + np.linalg.inv(W).dot(y - p)\n",
    "        tmp = X.T.dot(W)\n",
    "        _B = np.dot(np.linalg.inv(tmp.dot(X)), ( tmp.dot(z)))\n",
    "        if tolerance:\n",
    "            if np.linalg.norm(_B - B) < tolerance:\n",
    "                return B if not get_cost else (B, cost_function(X, y, beta))\n",
    "        B = _B\n",
    "    return B if not get_cost else (B, cost_function(X, y, beta))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='experiments'></a>\n",
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:15.891132Z",
     "start_time": "2021-04-07T16:29:15.884567Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:16.105967Z",
     "start_time": "2021-04-07T16:29:15.894651Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "beta = gradient_descent(X_train, y_train, l_rate=0.1)\n",
    "pred = (sigmoid(X_test, beta) > 0.5).astype(int)\n",
    "res = calculate_scores(y_test, pred)\n",
    "print(f'The resulting accuracy is {res[\"acc\"]*100:.2f}%')\n",
    "res[\"conf_matrix\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:17.956059Z",
     "start_time": "2021-04-07T16:29:16.109771Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "beta = SGD(X_train, y_train, l_rate=0.1)\n",
    "pred = (sigmoid(X_test, beta) > 0.5).astype(int)\n",
    "res = calculate_scores(y_test, pred)\n",
    "print(f'The resulting accuracy is {res[\"acc\"]*100:.2f}%')\n",
    "res[\"conf_matrix\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:19.024482Z",
     "start_time": "2021-04-07T16:29:17.960261Z"
    }
   },
   "outputs": [],
   "source": [
    "beta = IRLS(X_train, y_train, tolerance=0.0005)\n",
    "pred = (sigmoid(X_test, beta) > 0.5).astype(int)\n",
    "res = calculate_scores(y_test, pred)\n",
    "print(f'The resulting accuracy is {res[\"acc\"]*100:.2f}%')\n",
    "res[\"conf_matrix\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:19.038183Z",
     "start_time": "2021-04-07T16:29:19.029627Z"
    }
   },
   "outputs": [],
   "source": [
    "def performance_over_iterations(X, y, iterations : int, opt_method, n=10, tol=None):\n",
    "    acc_list = []\n",
    "    for i in range(n):\n",
    "        beta = opt_method(X, y, n_iter = iterations, tolerance=tol)\n",
    "        pred = (sigmoid(X_test, beta) > 0.5).astype(int)\n",
    "        acc_list.append(calculate_scores(y_test, pred)['acc'])\n",
    "    return [iterations, np.mean(acc_list)]\n",
    "\n",
    "from_iter, to_iter, step_size = 1, 101, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:25.653308Z",
     "start_time": "2021-04-07T16:29:19.044747Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "gd_iter_acc_list = [performance_over_iterations(X_train, y_train, iters, gradient_descent) \n",
    "                    for iters in tqdm(range(from_iter, to_iter, step_size))]\n",
    "gd_iter_acc = pd.DataFrame (gd_iter_acc_list,columns=['Iteration', 'Accuracy'])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data= gd_iter_acc, x = \"Iteration\", y = \"Accuracy\").set_title(\"Gradient Descent accuracy / iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:29:54.610690Z",
     "start_time": "2021-04-07T16:29:25.664887Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "sgd_iter_acc_list = [performance_over_iterations(X_train, y_train, iters, SGD) \n",
    "                     for iters in tqdm(range(from_iter, to_iter, step_size))]\n",
    "sgd_iter_acc = pd.DataFrame (sgd_iter_acc_list,columns=['Iteration', 'Accuracy'])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data= sgd_iter_acc, x = \"Iteration\", y = \"Accuracy\").set_title(\"Stochastic Gradient Descent accuracy / iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:30:06.110373Z",
     "start_time": "2021-04-07T16:29:54.618500Z"
    }
   },
   "outputs": [],
   "source": [
    "irls_iter_acc_list = [performance_over_iterations(X_train, y_train, iters, IRLS, n=1) \n",
    "                      for iters in tqdm(range(1, 15))]\n",
    "irls_iter_acc = pd.DataFrame (irls_iter_acc_list,columns=['Iteration', 'Accuracy'])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data= irls_iter_acc, x = \"Iteration\", y = \"Accuracy\").set_title(\"IRLS accuracy / iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:30:06.176840Z",
     "start_time": "2021-04-07T16:30:06.145682Z"
    }
   },
   "outputs": [],
   "source": [
    "gd_iter_acc.loc[:, 'method'] = 'GD'\n",
    "sgd_iter_acc.loc[:, 'method'] = 'SGD'\n",
    "irls_iter_acc.loc[:, 'method'] = 'IRLS'\n",
    "df = pd.concat([gd_iter_acc, sgd_iter_acc, irls_iter_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:30:09.588358Z",
     "start_time": "2021-04-07T16:30:06.181747Z"
    }
   },
   "outputs": [],
   "source": [
    "px.line(df, x='Iteration', y='Accuracy', color='method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:30:09.600830Z",
     "start_time": "2021-04-07T16:30:09.594366Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost_over_iterations(X, y, iterations : int, opt_method, n=10, tol=None):\n",
    "    cost_list = []\n",
    "    for i in range(n):\n",
    "        beta, cost = opt_method(X, y, n_iter = iterations, tolerance=None, get_cost=True)\n",
    "        cost_list.append(cost)\n",
    "    return [iterations, np.mean(cost_list)]\n",
    "\n",
    "from_iter, to_iter, step_size = 1, 101, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:30:16.435752Z",
     "start_time": "2021-04-07T16:30:09.605316Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "gd_iter_loglike_list = [cost_over_iterations(X_train, y_train, iters, gradient_descent) \n",
    "                    for iters in tqdm(range(from_iter, to_iter, step_size))]\n",
    "gd_iter_loglike = pd.DataFrame (gd_iter_loglike_list,columns=['Iteration', 'Log likelihood'])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data= gd_iter_loglike, x = \"Iteration\", y = \"Log likelihood\").set_title(\"Gradient Descent Log likelihood / iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:31:24.022325Z",
     "start_time": "2021-04-07T16:30:16.440697Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "sgd_iter_loglike_list = [cost_over_iterations(X_train, y_train, iters, SGD) \n",
    "                    for iters in tqdm(range(from_iter, to_iter, step_size))]\n",
    "sgd_iter_loglike = pd.DataFrame (sgd_iter_loglike_list,columns=['Iteration', 'Log likelihood'])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data= sgd_iter_loglike, x = \"Iteration\", y = \"Log likelihood\").set_title(\"SGD Log likelihood / iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:31:30.949855Z",
     "start_time": "2021-04-07T16:31:24.029055Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "irls_iter_loglike_list = [cost_over_iterations(X_train, y_train, iters, IRLS, n=1) \n",
    "                    for iters in tqdm(range(1, 15))]\n",
    "irls_iter_loglike = pd.DataFrame (irls_iter_loglike_list,columns=['Iteration', 'Log likelihood'])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data= irls_iter_loglike, x = \"Iteration\", y = \"Log likelihood\").set_title(\"IRLS Log likelihood / iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:31:30.965542Z",
     "start_time": "2021-04-07T16:31:30.953994Z"
    }
   },
   "outputs": [],
   "source": [
    "gd_iter_loglike.loc[:, 'method'] = 'GD'\n",
    "sgd_iter_loglike.loc[:, 'method'] = 'SGD'\n",
    "irls_iter_loglike.loc[:, 'method'] = 'IRLS'\n",
    "df = pd.concat([gd_iter_loglike, sgd_iter_loglike, irls_iter_loglike])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:31:31.059061Z",
     "start_time": "2021-04-07T16:31:30.973685Z"
    }
   },
   "outputs": [],
   "source": [
    "px.line(df, x='Iteration', y='Log likelihood', color='method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:31:31.071413Z",
     "start_time": "2021-04-07T16:31:31.063753Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost_over_iterations(X, y, iterations, opt_method, n=10, tol=1e-4, l_rate=0.01):\n",
    "    cost_list = []\n",
    "    for i in range(n):\n",
    "        beta, cost = opt_method(X, y, iterations, l_rate=l_rate, tolerance=None, get_cost=True)\n",
    "        cost_list.append(cost)\n",
    "    return [iterations, l_rate, np.mean(cost_list)]\n",
    "\n",
    "from_iter, to_iter, step_size = 1, 51, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:31:37.618004Z",
     "start_time": "2021-04-07T16:31:31.077238Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "gd_iter_acc_list = [cost_over_iterations(X_train, y_train, iters, gradient_descent, l_rate=l_rate) \n",
    "                    for iters in tqdm(range(from_iter, to_iter, step_size))\n",
    "                    for l_rate in np.logspace(-1, -6, 6)]\n",
    "gd_iter_acc = pd.DataFrame (gd_iter_acc_list,columns=['Iteration', 'lr', 'Log likelihood'])\n",
    "\n",
    "px.line(gd_iter_acc, x='Iteration', y='Log likelihood', color='lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:33:17.541792Z",
     "start_time": "2021-04-07T16:31:37.631032Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "gd_iter_acc_list = [cost_over_iterations(X_train, y_train, iters, SGD, l_rate=l_rate) \n",
    "                    for iters in tqdm(range(from_iter, to_iter, step_size))\n",
    "                    for l_rate in np.logspace(-1, -6, 6)]\n",
    "gd_iter_acc = pd.DataFrame (gd_iter_acc_list,columns=['Iteration', 'lr', 'Log likelihood'])\n",
    "\n",
    "px.line(gd_iter_acc, x='Iteration', y='Log likelihood', color='lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing against other methods form sickit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:33:17.590116Z",
     "start_time": "2021-04-07T16:33:17.546539Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, max_iter=1000).fit(X_train[:, 1:], y_train)\n",
    "clf.score(X_test[:, 1:], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:33:17.603081Z",
     "start_time": "2021-04-07T16:33:17.594324Z"
    }
   },
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:33:18.126959Z",
     "start_time": "2021-04-07T16:33:17.608525Z"
    }
   },
   "outputs": [],
   "source": [
    "nca = NeighborhoodComponentsAnalysis(random_state=42, max_iter=1000)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "nca_pipe.fit(X_train[:, 1:], y_train)\n",
    "nca_pipe.score(X_test[:, 1:], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA ftom sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:33:18.164408Z",
     "start_time": "2021-04-07T16:33:18.135836Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = LinearDiscriminantAnalysis().fit(X_train[:, 1:], y_train)\n",
    "clf.score(X_test[:, 1:], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QDA from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:33:18.185367Z",
     "start_time": "2021-04-07T16:33:18.172282Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = QuadraticDiscriminantAnalysis().fit(X_train[:, 1:], y_train)\n",
    "clf.score(X_test[:, 1:], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:33:18.200512Z",
     "start_time": "2021-04-07T16:33:18.196159Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets_list = ['banknote', 'diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:33:18.212184Z",
     "start_time": "2021-04-07T16:33:18.206348Z"
    }
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=0, max_iter=1000)\n",
    "\n",
    "nca = NeighborhoodComponentsAnalysis(random_state=42, max_iter=1000)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn = Pipeline([('nca', nca), ('knn', knn)])\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:34:08.891144Z",
     "start_time": "2021-04-07T16:34:02.956289Z"
    }
   },
   "outputs": [],
   "source": [
    "for dataset_name in datasets_list:\n",
    "    X, y = datasets[dataset_name]\n",
    "    X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "    for name, our_method in zip(['GD', 'SGD', 'IRLS'], [gradient_descent, SGD, IRLS]):\n",
    "        beta = our_method(X_train, y_train, n_iter=1000, tolerance=0.001)\n",
    "        pred = (sigmoid(X_test, beta) > 0.5).astype(int)\n",
    "        res = calculate_scores(y_test, pred, beta=beta)\n",
    "        print(dataset_name, name, res['acc'])\n",
    "    for name, sklearn_method in zip(['LR', 'kNN', 'LDA', 'QDA'], [log_reg, knn, lda, qda]):\n",
    "        sklearn_method.fit(X_train[:, 1:], y_train)\n",
    "        pred = sklearn_method.predict(X_test[:, 1:])\n",
    "        res = calculate_scores(y_test, pred, beta=beta)\n",
    "        print(dataset_name, name, res['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mock data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:33:22.416490Z",
     "start_time": "2021-04-07T16:33:22.135820Z"
    }
   },
   "outputs": [],
   "source": [
    "# lets create simple dataset consiting of N point in R2 that can belong to 2 classes\n",
    "N = 1000\n",
    "X = np.random.randn(N * 2).reshape(N, 2) - 1\n",
    "X[:N//2] = X[:N//2] + 2\n",
    "y = np.array([0] * (N//2) + [1] * (N//2))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=y)\n",
    "show_plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:33:22.455349Z",
     "start_time": "2021-04-07T16:33:22.436365Z"
    }
   },
   "outputs": [],
   "source": [
    "# add column of ones to include intercept in the model\n",
    "intercept = np.ones((X.shape[0], 1))\n",
    "X = np.concatenate((intercept, X), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:33:22.666425Z",
     "start_time": "2021-04-07T16:33:22.466151Z"
    }
   },
   "outputs": [],
   "source": [
    "beta = gradient_descent(X, y, l_rate=1e-4)\n",
    "pred = (sigmoid(X, beta) > 0.5).astype(int)\n",
    "res = calculate_scores(y, pred)\n",
    "print(f'The resulting accuracy is {res[\"acc\"]*100:.2f}%')\n",
    "res['conf_matrix'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:33:23.039127Z",
     "start_time": "2021-04-07T16:33:22.671850Z"
    }
   },
   "outputs": [],
   "source": [
    "beta = SGD(X, y, l_rate=1e-4)\n",
    "pred = (sigmoid(X, beta) > 0.5).astype(int)\n",
    "res = calculate_scores(y, pred)\n",
    "print(f'The resulting accuracy is {res[\"acc\"]*100:.2f}%')\n",
    "res['conf_matrix'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:33:23.889407Z",
     "start_time": "2021-04-07T16:33:23.046911Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is low because IRLS is fucking up with the added intercept column, if you remove the intercept\n",
    "# works as intended, I'll need to check on that maybe tomorrow\n",
    "beta = IRLS(X, y, n_iter=1000, )\n",
    "pred = (sigmoid(X, beta) > 0.5).astype(int)\n",
    "res = calculate_scores(y, pred)\n",
    "print(f'The resulting accuracy is {res[\"acc\"]*100:.2f}%')\n",
    "res['conf_matrix'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T16:33:24.207689Z",
     "start_time": "2021-04-07T16:33:23.896265Z"
    }
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(-5, 5, 100)\n",
    "yy = np.linspace(-5, 5, 100)\n",
    "xx, yy = np.meshgrid(xx, yy)\n",
    "xx, yy = xx.flatten(), yy.flatten()\n",
    "mock_data = np.array([np.ones(len(xx)), xx, yy]).T\n",
    "values = sigmoid(mock_data, beta)\n",
    "go.Figure(\n",
    "    [\n",
    "        go.Contour(x=xx, y=yy, z=values),\n",
    "        go.Scatter(x=X[y==0, 1], y=X[y==0, 2], mode='markers', marker_color='red'),\n",
    "        go.Scatter(x=X[y==1, 1], y=X[y==1, 2], mode='markers', marker_color='blue')\n",
    "    ],\n",
    "    layout=dict(\n",
    "        xaxis=dict(scaleanchor='y', scaleratio=1),\n",
    "        width=600, height=600,\n",
    "        showlegend=False\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
